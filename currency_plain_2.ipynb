{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "currency_plain_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemankundu/indian-currency-recognizer/blob/master/currency_plain_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Gm6Ud3PFlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9lFOLzXmqR2",
        "colab_type": "code",
        "outputId": "7472f52f-7284-4203-e29b-4b87f9a503fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "#from shutil import copy\n",
        "import shutil\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing as prep\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r6SqxKfRCZN",
        "colab_type": "code",
        "outputId": "c5315abd-0bcb-49ed-996d-9a8169baa022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#setup drive path and data directory\n",
        "drive_path = '/content/drive/My Drive/colab/currency/'\n",
        "data_dir = drive_path + \"dataset_plain/pending/\"\n",
        "classes = os.listdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9f85346b1bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdrive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/colab/currency/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"dataset_plain/pending/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/colab/currency/dataset_plain/pending/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3zDfaawmmAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nNfQt0hlAXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating training,  testing sb directories for each class\n",
        "if not os.path.exists(drive_path + 'dataset_plain/tmp/'):\n",
        "  os.mkdir(drive_path + 'dataset_plain/tmp/')\n",
        "if not os.path.exists(drive_path + 'dataset_plain/tmp/currency'):\n",
        "  os.mkdir(drive_path + 'dataset_plain/tmp/currency')\n",
        "training_dir = 'dataset_plain/tmp/currency/training/'\n",
        "testing_dir = 'dataset_plain/tmp/currency/testing/'\n",
        "dev_dir = 'dataset_plain/tmp/currency/dev/'\n",
        "dirs = [training_dir, dev_dir, testing_dir]\n",
        "\n",
        "for dir_ in dirs:\n",
        "  dir_ = drive_path + dir_\n",
        "  if not os.path.exists(dir_):\n",
        "    os.mkdir(dir_)\n",
        "  for cls in classes:\n",
        "    cls_dir = dir_ + cls\n",
        "    if not os.path.exists(cls_dir):\n",
        "      print(\"creating \" , cls_dir)\n",
        "      os.mkdir(cls_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Hr7KJ9wQKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set training and testing directory path\n",
        "training_dir = drive_path + 'dataset_plain/tmp/currency/training/'\n",
        "testing_dir = drive_path + 'dataset_plain/tmp/currency/testing/'\n",
        "dev_dir = drive_path + 'dataset_plain/tmp/currency/dev/'\n",
        "dirs = [training_dir, dev_dir, testing_dir]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Qc9DBJUN_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split data into traing and testing\n",
        "def split_data(data_dir, training_dir, dev_dir, testing_dir, split):\n",
        "  dirs = [training_dir, dev_dir, testing_dir]\n",
        "  if sum(split) > 1.0:\n",
        "    print('Invalid split')\n",
        "    return\n",
        "  for cls in classes:\n",
        "    print(cls)\n",
        "    data = os.listdir(data_dir + cls)\n",
        "    shuffle(data)\n",
        "    i = 0\n",
        "    for dir_, sp in zip(dirs, split):\n",
        "      for _ in range(int(len(data)*sp)):\n",
        "        shutil.copy(data_dir + cls + '/' + data[i], dir_+ cls)\n",
        "        if (len(data)/(i+1))%5 == 0:\n",
        "          print((len(data))-(len(data)/(i+1)))\n",
        "        i += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hl1AoxJu-xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_data(data_dir, training_dir, dev_dir, testing_dir, [.9, .0, 0.1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37bQnXBzs1jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hepler function for cloning virtual instance's tmp folder to drive's tmp folder\n",
        "import os, glob, shutil\n",
        "\n",
        "def make_dir(path):\n",
        "    if not os.path.isdir(path):\n",
        "        os.mkdir(path)\n",
        "\n",
        "def copy_dir(source_item, destination_item):\n",
        "    if os.path.isdir(source_item):\n",
        "        make_dir(destination_item)\n",
        "        sub_items = glob.glob(source_item + '/*')\n",
        "        for sub_item in sub_items:\n",
        "            copy_dir(sub_item, destination_item + '/' + sub_item.split('/')[-1])\n",
        "    else:\n",
        "      try:\n",
        "        shutil.copy(source_item, destination_item)\n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "copy_dir(\"/tmp\", drive_path+'tmp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SotbQwT_6fPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print count of files present in each directory\n",
        "for dir_ in dirs:\n",
        "  #print(dir_, len(os.listdir(dir_)))\n",
        "  for cls in classes:\n",
        "    print(dir_ + cls, len(os.listdir(dir_ + cls)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LTZvp1XvzuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#crop the images, so that we get only currency part of it, w/o any background\n",
        "import cv2\n",
        "from os.path import basename\n",
        "from glob import glob\n",
        "\n",
        "def get_contours(img):\n",
        "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    ret, thresh = cv2.threshold(imgray, 150, 255, 0)\n",
        "    img2, contours, hierarchy = cv2.findContours(thresh, 1, 2)\n",
        "\n",
        "    # filter contours that are too large or small\n",
        "    size = get_size(img)\n",
        "    contours = [cc for cc in contours if contourOK(cc, size)]\n",
        "    return contours\n",
        "\n",
        "def get_size(img):\n",
        "    ih, iw = img.shape[:2]\n",
        "    return iw * ih\n",
        "\n",
        "def contourOK(cc, size=1000000):\n",
        "    x, y, w, h = cv2.boundingRect(cc)\n",
        "    if w < 50 or h < 50: return False # too narrow or wide is bad\n",
        "    area = cv2.contourArea(cc)\n",
        "    rt = area < (size * 0.8) and area > 200\n",
        "    if not rt:\n",
        "      print(\"ignoring..\")\n",
        "    return rt\n",
        "\n",
        "def find_boundaries(img, contours):\n",
        "    ih, iw = img.shape[:2]\n",
        "    minx = iw\n",
        "    miny = ih\n",
        "    maxx = 0\n",
        "    maxy = 0\n",
        "\n",
        "    for cc in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cc)\n",
        "        if x < minx: minx = x\n",
        "        if y < miny: miny = y\n",
        "        if x + w > maxx: maxx = x + w\n",
        "        if y + h > maxy: maxy = y + h\n",
        "\n",
        "    return (minx, miny, maxx, maxy)\n",
        "\n",
        "def crop(img, boundaries):\n",
        "    minx, miny, maxx, maxy = boundaries\n",
        "    return img[miny:maxy, minx:maxx]\n",
        "\n",
        "def process_image(path, fname):\n",
        "    img = cv2.imread(path + fname)\n",
        "    contours = get_contours(img)\n",
        "    #cv2.drawContours(img, contours, -1, (0,255,0)) # draws contours, good for debugging\n",
        "    bounds = find_boundaries(img, contours)\n",
        "    cropped = crop(img, bounds)\n",
        "    #if get_size(cropped) < 400: return # too small\n",
        "    cv2.imwrite(path + fname, cropped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh609jxzwUSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calling crop function\n",
        "for cls in classes:\n",
        "  print(cls)\n",
        "  path = drive_path + 'dataset_plain/tmp/currency/training/' + cls\n",
        "  l = os.listdir(path)\n",
        "  for f in l:\n",
        "    try:\n",
        "      process_image( path + '/' , f)\n",
        "    except Exception:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41zk_SXK5esE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#helper function to delete data from tmp folder when training is done\n",
        "for cls in classes:\n",
        "  print(cls)\n",
        "  path = drive_path + 'dataset_plain/tmp/currency/training/' + cls\n",
        "  l = os.listdir(path)\n",
        "  for f in l:\n",
        "    try:\n",
        "      if os.path.getsize(path + '/' + f) == 0:\n",
        "        os.remove(path + '/' + f)\n",
        "        print(\"Deleted..\")\n",
        "    except Exception:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq28taEF_bpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6OUtaO9uNZW",
        "colab_type": "code",
        "outputId": "0a303474-7f72-4cdf-e75e-3904f8b62958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#setup data generators for image dataa augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True , shear_range = 0.2, fill_mode='nearest' , rescale=1.0/255.0, \n",
        "                                      rotation_range=10, width_shift_range= 0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "train_generator = train_datagen.flow_from_directory(training_dir, target_size=(dim, dim), batch_size=64)\n",
        "test_datagen = ImageDataGenerator(horizontal_flip=True , shear_range = 0.2, fill_mode='nearest' , rescale=1.0/255.0, \n",
        "                                      rotation_range=10, width_shift_range= 0.1, height_shift_range=0.1, zoom_range=0.1)\n",
        "test_generator = test_datagen.flow_from_directory(testing_dir, target_size=(dim, dim), batch_size=64)\n",
        "#test_datagen = ImageDataGenerator(rescale=1.0/255.0, rotation_range=40, width_shift_range= 0.1, height_shift_range=0.1, zoom_range=0.1 )\n",
        "#test_generator = test_datagen.flow_from_directory(testing_dir, target_size=(dim, dim), batch_size=64)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1159 images belonging to 9 classes.\n",
            "Found 126 images belonging to 9 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkyabuAUwj8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the model\n",
        "from tensorflow.keras import regularizers\n",
        "l2 = 0.01\n",
        "built_model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(dim, dim, 3)),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.MaxPool2D(), \n",
        "tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.MaxPool2D(),  \n",
        "tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "tf.keras.layers.Dropout(rate=0.2),\n",
        "tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.MaxPool2D(), \n",
        "tf.keras.layers.Dropout(rate=0.2),\n",
        "tf.keras.layers.Conv2D(128, 3,  activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.MaxPool2D(), \n",
        "tf.keras.layers.Dropout(rate=0.2), \n",
        "tf.keras.layers.Conv2D(256, 3,  activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.MaxPool2D(), \n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(1024, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(512, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(256, activation='relu'),\n",
        "tf.keras.layers.Dense(9, activation='softmax'),          \n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGCh8wChbu3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "built_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMo-YnYk8RCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"cnn_l2_5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J75USF63O0ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to save only the model architecture\n",
        "with open(drive_path + \"dataset_plain/\" + model_name + \".json\", \"w\") as f:\n",
        "  f.write(built_model.to_json())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eQhuTTik-kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to load a model from saved json file\n",
        "json_file = open(drive_path + \"dataset_plain/\" + model_name + \".json\", 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "built_model = tf.keras.models.model_from_json(loaded_model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfg9inc_6-PT",
        "colab_type": "code",
        "outputId": "7721eb7e-174e-4304-92dd-a5671c77f5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#to load a model weights, with two modes: full is manually saved version, and auto is auto-saved version\n",
        "saved_version = \"full\"\n",
        "loaded_model = tf.keras.models.load_model(drive_path + \"dataset_plain/\"  + model_name + '_'+ saved_version +'.h5')\n",
        "for layer_loaded, layer_built in zip(loaded_model.layers, built_model.layers):\n",
        "   layer_built.set_weights(layer_loaded.get_weights())\n",
        "#loaded_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9jgtyj8fbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model\n",
        "built_model.compile(optimizer=Adam(learning_rate=0.0001) , loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z43mEhGS9LPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setup callback to auto-save model weights after each epoch\n",
        "checkpoint = callbacks.ModelCheckpoint(drive_path + \"dataset_plain/\"  + model_name +'_auto.h5', monitor='loss', verbose=1, save_best_only=False, mode='min', overwrite=True)\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAQ3Z9US1xqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit model, can be run using loop or specifying epoch\n",
        "history = []\n",
        "for i in range(1):\n",
        "  print(\"\\nloop: \", i)\n",
        "  history.append(built_model.fit_generator(train_generator,\n",
        "                              epochs=100,\n",
        "                              verbose=1,\n",
        "                              validation_data=test_generator,\n",
        "                              callbacks=callbacks_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PdU1kFq4ChB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to manually save the model\n",
        "built_model.save(drive_path + \"dataset_plain/\" + model_name + '_full.h5')\n",
        "built_model.save_weights(drive_path + \"dataset_plain/\" + model_name + '_w.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF4I3mfoa9xA",
        "colab_type": "code",
        "outputId": "a54c2fa6-f179-4f9e-f459-7f8602297abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "#convert the model to tflite version\n",
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model_file(drive_path + \"dataset_plain/\" + model_name + '_full.h5')\n",
        "tfmodel = converter.convert()\n",
        "open (drive_path + \"dataset_plain/\" + model_name + \"_full.tflite\" , \"wb\").write(tfmodel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 40 variables.\n",
            "INFO:tensorflow:Converted 40 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8693060"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDRAq2QGboIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DygHwvYxKnJZ",
        "colab_type": "code",
        "outputId": "54e84b20-7794-475a-a287-017fbe07e4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#evaluation\n",
        "built_model.evaluate_generator(test_generator, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 470ms/step - loss: 0.2998 - acc: 0.9365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29984238743782043, 0.93650794]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAhBRtmH06FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in case while model fitting epochs is used instead of loops\n",
        "history = history[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfNnHV4xkGxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLOT LOSS AND ACCURACY\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxLMiCoscmPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#actual indecies of classes that the datagenerator is using\n",
        "#here we inerchange key with value of the dictionary\n",
        "classes_form_gen = dict([(v, k) for (k, v) in test_generator.class_indices.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAFiZiWtkfLY",
        "colab_type": "code",
        "outputId": "20c759e6-0f98-481c-916e-3f9d1c122f3b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "#To upload own image and test the prediction\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(dim, dim))\n",
        "  # img = cv2.imread(path)\n",
        "  # img = cv2.resize(img, (dim, dim))\n",
        "  x = image.img_to_array(img)\n",
        "  x = x/255.0\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  #print(x)\n",
        "  #images = np.vstack([x])\n",
        "  prediction = built_model.predict(x)\n",
        "  print(prediction)\n",
        "  prediction = prediction[0]\n",
        "  bestclass = 0\n",
        "  for i in range(len(classes_form_gen)):\n",
        "    if (prediction[i] > prediction[bestclass]):\n",
        "      bestclass = i\n",
        "  print('\\nI think this is a ' + classes_form_gen[bestclass] + ' with ' + str(prediction[bestclass] * 100) + '% confidence.')\n",
        "  #print(\"I think this is a \", classes_form_gen[prediction.index(max(prediction))])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ce1e77ed-2ccb-4192-85ef-75c5c0a1d3ba\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ce1e77ed-2ccb-4192-85ef-75c5c0a1d3ba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cap0_1.jpg to cap0_1.jpg\n",
            "[[4.6499739e-08 2.4789435e-04 2.0394781e-07 4.2128550e-09 5.5666597e-08\n",
            "  7.3576297e-07 1.5899574e-04 9.9959046e-01 1.6079370e-06]]\n",
            "\n",
            "I think this is a twohundred with 99.95904564857483% confidence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH7Jpg2fpm15",
        "colab_type": "code",
        "outputId": "660b4356-3215-411b-d9cd-7ca27c2fdecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "#to check number of missclassified data of each class\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "for cls in classes_form_gen.values():\n",
        "  cnt = 0\n",
        "  print(cls, \"-\"*(30-len(str(cls))))\n",
        "  path = drive_path + 'dataset_plain/tmp/currency/testing/' + cls\n",
        "  l = os.listdir(path)\n",
        "  for f in l:\n",
        "    img = image.load_img(path + '/' + f, target_size=(dim, dim))\n",
        "    # img = cv2.imread(path + '/' + f)\n",
        "    # img = cv2.resize(img, (dim, dim))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    prediction = built_model.predict(x)\n",
        "    prediction = prediction[0]\n",
        "    bestclass = 0\n",
        "    for i in range(len(classes_form_gen)):\n",
        "      if (prediction[i] > prediction[bestclass]):\n",
        "        bestclass = i\n",
        "    #print(classes_form_gen[bestclass], prediction[bestclass])\n",
        "    if classes_form_gen[bestclass] == cls:\n",
        "      cnt += 1\n",
        "    else:\n",
        "      print(classes_form_gen[bestclass], int(prediction[train_generator.class_indices[cls]]*100))\n",
        "  print(\"Correct Incorrect: \", cnt, len(l)-cnt)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fifty_2 -----------------------\n",
            "Correct Incorrect:  15 0\n",
            "five --------------------------\n",
            "Correct Incorrect:  14 0\n",
            "fivehundred_2 -----------------\n",
            "Correct Incorrect:  13 0\n",
            "hundred -----------------------\n",
            "Correct Incorrect:  3 0\n",
            "hundred_2 ---------------------\n",
            "hundred 2\n",
            "hundred 20\n",
            "Correct Incorrect:  14 2\n",
            "ten_2 -------------------------\n",
            "Correct Incorrect:  26 0\n",
            "twenty_2 ----------------------\n",
            "Correct Incorrect:  15 0\n",
            "twohundred --------------------\n",
            "fivehundred_2 2\n",
            "fivehundred_2 4\n",
            "fivehundred_2 1\n",
            "Correct Incorrect:  12 3\n",
            "twothousand -------------------\n",
            "Correct Incorrect:  9 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqc8rPOKnXww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_generator.class_indices[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecr0R2J2nY-S",
        "colab_type": "code",
        "outputId": "5b13b66a-a96d-430c-9c95-718bbe954f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'fifty_2',\n",
              " 1: 'five',\n",
              " 2: 'fivehundred_2',\n",
              " 3: 'hundred',\n",
              " 4: 'hundred_2',\n",
              " 5: 'ten_2',\n",
              " 6: 'twenty_2',\n",
              " 7: 'twohundred',\n",
              " 8: 'twothousand'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3fnvPmB_0bi",
        "colab_type": "code",
        "outputId": "b224383c-1182-4921-cad8-1acf8fa4dff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi       #Get Details about GPU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 30 04:43:39 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fgQAguaH9qG",
        "colab_type": "code",
        "outputId": "628d2463-f14a-4842-8a5e-17de46a5a11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat /proc/cpuinfo      #Get CPU Information"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 4\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 2\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}